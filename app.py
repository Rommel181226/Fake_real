# -*- coding: utf-8 -*-
"""NLP_activity.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/185GArz9w6f3DVlHbCDpaB1Hw8lLQN27R
"""

# sentiment_app.py

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import nltk
import string
import re
from collections import Counter
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.corpus import stopwords
import nltk
nltk.download('punkt')  # For tokenization
nltk.download('stopwords')  # For stopword list

# Downloads (only once)
nltk.download('vader_lexicon')
nltk.download('stopwords')

# Load and cache data
@st.cache_data
def load_data():
    df = pd.read_csv("/content/reduced_news_data.csv")
    return df

df = load_data()

# Clean text function
stop_words = set(stopwords.words('english'))

def clean_text(text):
    if not isinstance(text, str):
        return ""
    text = text.lower()
    text = re.sub(r'\d+', '', text)
    text = text.translate(str.maketrans('', '', string.punctuation))
    words = text.split()
    words = [w for w in words if w not in stop_words and len(w) > 2]
    return " ".join(words)

# Cleaned text
df['cleaned_text'] = df['text'].apply(clean_text)

# Sentiment Analysis
sia = SentimentIntensityAnalyzer()
df['sentiment'] = df['text'].apply(lambda x: sia.polarity_scores(str(x))['compound'])
df['sentiment_category'] = df['sentiment'].apply(
    lambda score: 'Positive' if score > 0.05 else ('Negative' if score < -0.05 else 'Neutral')
)

# Sidebar Filters
st.sidebar.title("Filters")
subject_filter = st.sidebar.multiselect("Select Subject(s)", df['subject'].unique(), default=df['subject'].unique())
df_filtered = df[df['subject'].isin(subject_filter)]

# Tabs
tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs([
    "📋 Overview", "🎭 Visualizing Genres", "🧹 Cleaned Genre Words",
    "📊 Word Frequency", "📈 Sentiment Distribution",
    "⚖️ Sentiment Comparison", "🔠 Top Words by Subject", "📚 Subject Sentiment"
])

with tab1:
    st.header("📋 Overview")
    st.write(f"**Total Records:** {df.shape[0]}")
    st.dataframe(df_filtered[['title', 'subject', 'date']].head(10))

with tab2:
    st.header("🎭 Genre Counts")
    st.bar_chart(df['subject'].value_counts())

with tab3:
    st.header("🧹 Visualizing Cleaned Genres")
    genre_words = " ".join(df_filtered['cleaned_text']).split()
    word_freq = Counter(genre_words).most_common(20)
    words, counts = zip(*word_freq)
    fig, ax = plt.subplots()
    ax.bar(words, counts, color='skyblue')
    plt.xticks(rotation=45)
    st.pyplot(fig)

with tab4:
    st.header("📊 Word Frequency Comparison")
    st.write("Top 10 Words Per Selected Subject")
    for subject in subject_filter:
        subject_df = df[df['subject'] == subject]
        subject_words = " ".join(subject_df['cleaned_text']).split()
        top_words = Counter(subject_words).most_common(10)
        st.subheader(subject)
        st.write(top_words)

with tab5:
    st.header("📈 Sentiment Distribution")
    fig, ax = plt.subplots()
    ax.hist(df_filtered['sentiment'], bins=30, color='lightgreen', edgecolor='black')
    ax.set_title("Sentiment Score Histogram")
    ax.set_xlabel("Compound Sentiment Score")
    ax.set_ylabel("Frequency")
    st.pyplot(fig)

with tab6:
    st.header("⚖️ Sentiment Comparison by Category")
    st.bar_chart(df_filtered['sentiment_category'].value_counts())

with tab7:
    st.header("🔠 Top Words by Subject")
    for subject in subject_filter:
        words = " ".join(df[df['subject'] == subject]['cleaned_text']).split()
        top_words = Counter(words).most_common(10)
        st.subheader(subject)
        st.write(pd.DataFrame(top_words, columns=["Word", "Frequency"]))

with tab8:
    st.header("📚 Sentiment Description per Subject")
    st.dataframe(df.groupby('subject')['sentiment'].describe())
